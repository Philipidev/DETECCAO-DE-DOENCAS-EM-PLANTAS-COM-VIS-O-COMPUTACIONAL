{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!py --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tqdm\n",
    "%pip install ipywidgets\n",
    "%pip install jupyterlab_widgets\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Repositorios/Meus/PAI-Detecao-de-doencas-em-plantas-com-visao-computacional/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório de treino: data/raw/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\n",
      "Diretório de validação: data/raw/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\n",
      "Diretório de teste: data/raw/new-plant-diseases-dataset/test/test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "# Diretório dos dados brutos\n",
    "DATA_DIR = \"/mnt/c/Repositorios/Meus/PAI-Detecao-de-doencas-em-plantas-com-visao-computacional/data/raw/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/\"\n",
    "\n",
    "# Subdiretórios para treino, validação e teste\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "VALID_DIR = os.path.join(DATA_DIR, \"valid\")\n",
    "TEST_DIR = \"data/raw/new-plant-diseases-dataset/test/test\"\n",
    "\n",
    "print(f\"Diretório de treino: {TRAIN_DIR}\")\n",
    "print(f\"Diretório de validação: {VALID_DIR}\")\n",
    "print(f\"Diretório de teste: {TEST_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/raw/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Listar as classes no diretório de treino\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m classes \u001b[38;5;241m=\u001b[39m [d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_DIR\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(TRAIN_DIR, d))]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClasses disponíveis no dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantidade de classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(classes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/raw/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'"
     ]
    }
   ],
   "source": [
    "# Listar as classes no diretório de treino\n",
    "classes = [d for d in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, d))]\n",
    "print(f\"Classes disponíveis no dataset: {classes}\")\n",
    "print(f\"Quantidade de classes: {len(classes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar imagens por classe no conjunto de treino\n",
    "imagens_por_classe = {classe: len(glob(os.path.join(TRAIN_DIR, classe, \"*.JPG\"))) for classe in classes}\n",
    "\n",
    "# Mostrar os resultados\n",
    "for classe, count in imagens_por_classe.items():\n",
    "    print(f\"{classe}: {count} imagens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def visualizar_imagens(classe, n=5, dir_type=\"train\"):\n",
    "    \"\"\"\n",
    "    Visualiza imagens aleatórias de uma classe específica.\n",
    "\n",
    "    Args:\n",
    "        classe (str): Nome da classe.\n",
    "        n (int): Número de imagens a serem exibidas.\n",
    "        dir_type (str): Tipo de diretório ('train' ou 'valid').\n",
    "    \"\"\"\n",
    "    if dir_type == \"train\":\n",
    "        classe_dir = os.path.join(TRAIN_DIR, classe)\n",
    "    elif dir_type == \"valid\":\n",
    "        classe_dir = os.path.join(VALID_DIR, classe)\n",
    "    else:\n",
    "        raise ValueError(\"Tipo de diretório deve ser 'train' ou 'valid'\")\n",
    "    \n",
    "    imagens = glob(os.path.join(classe_dir, \"*.JPG\"))\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    for i in range(n):\n",
    "        img_path = random.choice(imagens)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(classe)\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Visualizar imagens da classe \"Apple___Apple_scab\"\n",
    "visualizar_imagens(\"Apple___Apple_scab\", n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "def carregar_dados_com_filtro(data_dir, classes, limite_por_classe=100):\n",
    "    \"\"\"\n",
    "    Carrega imagens e rótulos de um diretório específico mantendo o tamanho original (256x256),\n",
    "    com uma barra de progresso para exibir o status de carregamento. Limita o número de imagens por classe.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Diretório base dos dados.\n",
    "        classes (list): Lista das classes selecionadas.\n",
    "        limite_por_classe (int): Número máximo de imagens a carregar por classe.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Arrays de imagens (X) e rótulos (y).\n",
    "    \"\"\"\n",
    "    imagens = []\n",
    "    rotulos = []\n",
    "    \n",
    "    # Inicializa a barra de progresso\n",
    "    total_imagens = sum([min(len(glob(os.path.join(data_dir, classe, \"*.*\"))), limite_por_classe) for classe in classes])\n",
    "    progress_bar = tqdm(total=total_imagens, desc=\"Carregando imagens\", unit=\"imagens\")\n",
    "\n",
    "    for classe_idx, classe in enumerate(classes):\n",
    "        classe_dir = os.path.join(data_dir, classe)\n",
    "        imagens_classe = glob(os.path.join(classe_dir, \"*.*\"))[:limite_por_classe]  # Aceita qualquer extensão\n",
    "        for img_path in imagens_classe:\n",
    "            # Carrega e processa a imagem\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Erro ao carregar a imagem: {img_path}\")\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Converte para RGB\n",
    "            imagens.append(img / 255.0)  # Normalizar (escala 0 a 1)\n",
    "            rotulos.append(classe_idx)\n",
    "            \n",
    "            # Atualiza a barra de progresso\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    # Fecha a barra de progresso\n",
    "    progress_bar.close()\n",
    "    return np.array(imagens), np.array(rotulos)\n",
    "\n",
    "\n",
    "# Diretórios de treino e validação\n",
    "TRAIN_DIR = r\"C:\\Repositorios\\Meus\\PAI-Detecao-de-doencas-em-plantas-com-visao-computacional\\data\\raw\\new-plant-diseases-dataset\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\train\"\n",
    "VALID_DIR = r\"C:\\Repositorios\\Meus\\PAI-Detecao-de-doencas-em-plantas-com-visao-computacional\\data\\raw\\new-plant-diseases-dataset\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\valid\"\n",
    "\n",
    "# Classes selecionadas\n",
    "classes_selecionadas = [\n",
    "    \"Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\",\n",
    "    \"Corn_(maize)___Common_rust_\",\n",
    "    \"Corn_(maize)___Northern_Leaf_Blight\",\n",
    "    \"Corn_(maize)___healthy\",\n",
    "    # \"Grape___Black_rot\",\n",
    "    # \"Grape___Esca_(Black_Measles)\",\n",
    "    # \"Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\",\n",
    "    # \"Grape___healthy\",\n",
    "    # \"Orange___Haunglongbing_(Citrus_greening)\",\n",
    "    \"Potato___Early_blight\",\n",
    "    \"Potato___Late_blight\",\n",
    "    \"Potato___healthy\",\n",
    "    \"Tomato___Bacterial_spot\",\n",
    "    \"Tomato___Early_blight\",\n",
    "    \"Tomato___Late_blight\",\n",
    "    \"Tomato___Leaf_Mold\",\n",
    "    \"Tomato___Target_Spot\",\n",
    "    \"Tomato___Tomato_mosaic_virus\",\n",
    "    \"Tomato___Tomato_Yellow_Leaf_Curl_Virus\",\n",
    "    \"Tomato___healthy\"\n",
    "]\n",
    "\n",
    "# Carregar os dados de treino com filtro\n",
    "X_train, y_train = carregar_dados_com_filtro(TRAIN_DIR, classes_selecionadas, limite_por_classe=500)\n",
    "\n",
    "# Carregar os dados de validação com filtro\n",
    "X_valid, y_valid = carregar_dados_com_filtro(VALID_DIR, classes_selecionadas, limite_por_classe=100)\n",
    "\n",
    "print(f\"Conjunto de treino: {X_train.shape}, Rótulos: {y_train.shape}\")\n",
    "print(f\"Conjunto de validação: {X_valid.shape}, Rótulos: {y_valid.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Definir o modelo\n",
    "model = models.Sequential([\n",
    "    # Bloco 1\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # Bloco 2\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # Bloco 3\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # Bloco 4\n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # Camadas Fully Connected\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(classes_selecionadas), activation='softmax')  # Saída final\n",
    "])\n",
    "\n",
    "# Exibir o resumo do modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),  # Otimizador Adam com taxa de aprendizado ajustada\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Callbacks para treinamento\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Treinamento do modelo\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    epochs=100,  # Aumente para um número maior de épocas\n",
    "    batch_size=32,  # Ajuste com base na sua memória GPU\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Extrair detalhes do modelo\n",
    "optimizer_name = model.optimizer.__class__.__name__  # Nome do otimizador\n",
    "activation_name = model.layers[0].activation.__name__  # Função de ativação da primeira camada\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # Data e hora atuais\n",
    "\n",
    "# Nome dinâmico da pasta do modelo\n",
    "model_name = f\"PlantNet-DeepConv512-Robust_{timestamp}\"\n",
    "model_path = os.path.join(\"models\", model_name)\n",
    "\n",
    "# Criar a pasta do modelo, se não existir\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "print(f\"Gráficos serão salvos na pasta: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotar a acurácia\n",
    "plt.plot(history.history['accuracy'], label='Acurácia de Treinamento')\n",
    "plt.plot(history.history['val_accuracy'], label='Acurácia de Validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "plt.title('Acurácia ao longo das épocas')\n",
    "plt.savefig(os.path.join(model_path, 'accuracy.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plotar a perda\n",
    "plt.plot(history.history['loss'], label='Perda de Treinamento')\n",
    "plt.plot(history.history['val_loss'], label='Perda de Validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "plt.title('Perda ao longo das épocas')\n",
    "plt.savefig(os.path.join(model_path, 'loss.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# Predict probabilities for the validation set\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Find the index of the maximum probability\n",
    "# Create the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_valid, y_pred_classes)\n",
    "\n",
    "# Set the figure size before plotting\n",
    "plt.figure(figsize=(12, 10))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=classes_selecionadas)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical', colorbar=True)  # Remove figsize from here\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.savefig(os.path.join(model_path, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Gerar o relatório de classificação\n",
    "report = classification_report(y_valid, y_pred_classes, target_names=classes_selecionadas, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Plotar precisão, recall e f1-score por classe\n",
    "metrics = ['precision', 'recall', 'f1-score']\n",
    "report_df[metrics].iloc[:-3].plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Precisão, Recall e F1-Score por Classe')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Classe')\n",
    "plt.legend(['Precisão', 'Recall', 'F1-Score'])\n",
    "plt.savefig(os.path.join(model_path, 'precision_recall_f1.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Predições corretas\n",
    "correct = np.where(y_valid == y_pred_classes)[0]\n",
    "\n",
    "# Exibir 5 imagens corretamente classificadas\n",
    "plt.figure(figsize=(15, 8))  # Aumentar o tamanho da figura\n",
    "for i, idx in enumerate(random.sample(list(correct), 5)):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(X_valid[idx])\n",
    "    plt.title(\n",
    "        f\"Correto: {classes_selecionadas[y_valid[idx]]}\", \n",
    "        fontsize=8  # Reduzir o tamanho da fonte\n",
    "    )\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Predições Corretas\", fontsize=16)  # Ajustar o tamanho do título principal\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(model_path, 'predicoes_corretas.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predições erradas\n",
    "incorrect = np.where(y_valid != y_pred_classes)[0]\n",
    "\n",
    "# Exibir 5 imagens incorretamente classificadas\n",
    "plt.figure(figsize=(15, 8))  # Increase figure size for clarity\n",
    "for i, idx in enumerate(random.sample(list(incorrect), 5)):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(X_valid[idx])\n",
    "    plt.title(\n",
    "        f\"Errado: {classes_selecionadas[y_pred_classes[idx]]}\\nVerdade: {classes_selecionadas[y_valid[idx]]}\",\n",
    "        fontsize=8  # Reduce font size\n",
    "    )\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Predições Erradas\", fontsize=16)  # Adjust the overall title font size\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(model_path, 'predicoes_erradas.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calcular acurácia por classe\n",
    "class_accuracies = {}\n",
    "for i, classe in enumerate(classes_selecionadas):\n",
    "    idxs = np.where(y_valid == i)[0]\n",
    "    class_accuracy = accuracy_score(y_valid[idxs], y_pred_classes[idxs])\n",
    "    class_accuracies[classe] = class_accuracy\n",
    "\n",
    "# Plotar acurácia por classe\n",
    "plt.bar(class_accuracies.keys(), class_accuracies.values())\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Acurácia')\n",
    "plt.title('Acurácia por Classe')\n",
    "plt.savefig(os.path.join(model_path, 'accuracy_by_class.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar no conjunto de validação\n",
    "val_loss, val_accuracy = model.evaluate(X_valid, y_valid)\n",
    "print(f\"Perda no conjunto de validação: {val_loss:.4f}\")\n",
    "print(f\"Acurácia no conjunto de validação: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Escolher uma imagem aleatória do conjunto de validação\n",
    "idx = random.randint(0, len(X_valid) - 1)\n",
    "img = X_valid[idx]\n",
    "true_label = y_valid[idx]\n",
    "\n",
    "# Fazer a predição\n",
    "prediction = model.predict(img[np.newaxis, ...])  # Adiciona dimensão de batch\n",
    "predicted_label = classes_selecionadas[np.argmax(prediction)]\n",
    "\n",
    "# Visualizar a imagem e o resultado\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Previsto: {predicted_label}\\nVerdadeiro: {classes_selecionadas[true_label]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Gerar timestamp no formato YYYY_MM_DD_HH_MM_SS\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Salvar o modelo com a data no nome\n",
    "model.save(os.path.join(model_path, f'plant_disease_model_{timestamp}.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
